{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c79bea6b199f>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c79bea6b199f>\"\u001b[0;36m, line \u001b[0;32m80\u001b[0m\n\u001b[0;31m    for i in range(self.sample_num)\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# hand-written digit recognition (hdr)\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from numpy import matrix\n",
    "from scipy import optimize\n",
    "\n",
    "import math\n",
    "from math import pow\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "This class does some initial training of a neural network for predicting drawn\n",
    "digits based on a data set in data_matrix and data_labels. It can then be used to\n",
    "train the network further by calling train() with any array of data or to predict\n",
    "what a drawn digit is by calling predict().\n",
    "\n",
    "The weights that define the neural network can be saved to a file, NN_FILE_PATH,\n",
    "to be reloaded upon initilization.\n",
    "\"\"\"\n",
    "\n",
    "class HdrNeuralNetwork:\n",
    "    WIDTH_IN_PIXELS = 20\n",
    "    LEARNING_RATE = 0.1\n",
    "    # for online learning\n",
    "    NN_FILE_PATH = 'nn.json'\n",
    "\n",
    "    def __init__(self, num_hidden_nodes, data_matrix, data_labels, use_file=True):\n",
    "        self.LAMBDA = 0\n",
    "        # for regularization of the cost function\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self.sigmoid = np.vectorize(self._sigmoid_scalar)\n",
    "        self.sigmoid_prime = np.vectorize(self._sigmoid_prime_scalar)\n",
    "        self._use_file = use_file\n",
    "        self.data_matrix = data_matrix\n",
    "        self.data_labels = data_labels\n",
    "        self.sample_num = self.data_labels.shape[0]\n",
    "\n",
    "        if (not os.path.isfile(HdrNeuralNetwork.NN_FILE_PATH) or not use_file):\n",
    "            # Step 1: Initialize weights to small numbers\n",
    "            self.theta1 = self._rand_initialize_weights(self.num_hidden_nodes, 400+1)\n",
    "            # num_hidden_nodes*401 matrix, the one is the bias\n",
    "            self.theta2 = self._rand_initialize_weights(10, self.num_hidden_nodes+1)\n",
    "            # 10*(num_hidden_nodes+1) matrix, the one is the bias\n",
    "\n",
    "            # Train using sample data\n",
    "            TrainData = namedtuple('TrainData', ['fig', 'label'])\n",
    "            theta0 = np.asarray((0, 0)) \n",
    "            np.asarray(np.row_stack((self.theta1.flatten(1).T, self.theta2.flatten(1).T)))           \n",
    "            res = optimize.fmin_cg(nnCostFunction, x0, fprime=nnGrad, args=([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)]))\n",
    "            self.theta1 = np.reshape(res[0:self.num_hidden_nodes*401-1], (400+1, self.num_hidden_nodes)).T\n",
    "            self.theta2 = np.reshape(res[self.num_hidden_nodes*401:], (10, self.num_hidden_nodes+1)).T\n",
    "            # self.train([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)])\n",
    "            # The parameter is a list of tuples, or a list of dicts, which are called namedtuple\n",
    "            self.save()\n",
    "        else:\n",
    "            self._load()\n",
    "\n",
    "    def _rand_initialize_weights(self, size_in, size_out):\n",
    "        return [((x * 0.12) - 0.06) for x in np.random.rand(size_out, size_in)]\n",
    "\n",
    "    # The sigmoid activation function. Operates on scalars.\n",
    "    def _sigmoid_scalar(self, z):\n",
    "        return 1 / (1 + math.e ** -z)\n",
    "\n",
    "    def _sigmoid_prime_scalar(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def _draw(self, sample):\n",
    "        pixelArray = [sample[j:j+self.WIDTH_IN_PIXELS] for j in xrange(0, len(sample), self.WIDTH_IN_PIXELS)]\n",
    "        plt.imshow(zip(*pixelArray), cmap = cm.Greys_r, interpolation=\"nearest\")\n",
    "        plt.show()\n",
    "\n",
    "    def nnCostFunction(self, the_thetas, *args):\n",
    "        \n",
    "        theta1 = np.reshape(the_thetas[0:self.num_hidden_nodes*401-1], (400+1, self.num_hidden_nodes)).T\n",
    "        theta2 = np.reshape(the_thetas[self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "        training_data_array = args[0]\n",
    "        \n",
    "        J=0\n",
    "        \n",
    "        for data in training_data_array:\n",
    "            a1 = np.mat(data['fig']).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(np.mat(theta1), np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(np.mat(theta2), np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "            \n",
    "            for j in range(10):\n",
    "                J = J + np.mat(data['label']).T[j,0]*math.log(a3[j,0])+(1-np.mat(data['label']).T[j,0])*math.log(1-a3[j,0])\n",
    "            \n",
    "            J = -J/self.sample_num + self.LAMBDA/(2*self.sample_num)*(np.multiply(theta1[:,1:], theta1[:,1:]).sum()+np.multiply(theta1[:,1:], theta1[:,1:]).sum())\n",
    "        \n",
    "        return J\n",
    "        \n",
    "    def nnGrad(self, the_thetas, *args):\n",
    "        \n",
    "        theta1 = np.reshape(the_thetas[0:self.num_hidden_nodes*401-1], (self.num_hidden_nodes, 400+1)).T\n",
    "        theta2 = np.reshape(the_thetas[self.num_hidden_nodes*401:], (10, self.num_hidden_nodes+1)).T\n",
    "        training_data_array = args[0]\n",
    "        \n",
    "        Delta1 = np.zeros(np.mat(self.theta1).shape)\n",
    "        # num_hidden_nodes*401 matrix\n",
    "        Delta2 = np.zeros(np.mat(self.theta2).shape)\n",
    "        # 10*(num_hidden_nodes+1) matrix\n",
    "        theta1_grad = np.zeros(np.mat(self.theta1).shape)\n",
    "        theta2_grad = np.zeros(np.mat(self.theta2).shape)\n",
    "        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data['fig']).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(np.mat(theta1), np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(np.mat(theta2), np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data['label']] = 1\n",
    "            # 1*10 matrix\n",
    "            \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.row_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(np.mat(self.theta2).T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            \n",
    "            # Step 4: Sum delta*a.T and calculate the derivatives\n",
    "            Delta1 = self.Delta1 + np.dot(delta2, a1.T)\n",
    "            Delta2 = self.Delta2 + np.dot(delta3, a2.T)\n",
    "        \n",
    "        theta1_grad[:,0] = Delta1[:,0]/self.sample_num\n",
    "        theta2_grad[:,0] = Delta2[:,0]/self.sample_num\n",
    "        theta1_grad[:,1:] = Delta1[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta1[:,1:]\n",
    "        theta2_grad[:,1:] = Delta2[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta2[:,1:] \n",
    "        \n",
    "        return np.asarray(np.row_stack((theta1_grad.flatten(1).T, theta2_grad.flatten(1).T)))\n",
    "\n",
    "    def train(self, training_data_array):        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data['fig']).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(np.mat(self.theta1), np.column_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(np.mat(self.theta2), np.column_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data['label']] = 1\n",
    "            # 1*10 matrix\n",
    "            \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.column_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(np.mat(self.theta2).T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "\n",
    "            # Step 4: Update weights\n",
    "            self.theta1 -= self.LEARNING_RATE * np.dot(delta2, a1.T)\n",
    "            self.theta2 -= self.LEARNING_RATE * np.dot(delta3, a2.T)\n",
    "\n",
    "    def predict(self, test):\n",
    "        y1 = np.dot(np.mat(self.theta1), np.mat(test).T)\n",
    "        y1 =  y1 + np.mat(self.input_layer_bias) # Add the bias\n",
    "        y1 = self.sigmoid(y1)\n",
    "\n",
    "        y2 = np.dot(np.array(self.theta2), y1)\n",
    "        y2 = np.add(y2, self.hidden_layer_bias) # Add the bias\n",
    "        y2 = self.sigmoid(y2)\n",
    "\n",
    "        results = y2.T.tolist()[0]\n",
    "        return results.index(max(results))\n",
    "\n",
    "    def save(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        json_neural_network = {\n",
    "            \"theta1\":[np_mat.tolist()[0] for np_mat in self.theta1],\n",
    "            \"theta2\":[np_mat.tolist()[0] for np_mat in self.theta2],\n",
    "            \"b1\":self.input_layer_bias[0].tolist()[0],\n",
    "            \"b2\":self.hidden_layer_bias[0].tolist()[0]\n",
    "        };\n",
    "        with open(OCRNeuralNetwork.NN_FILE_PATH,'w') as nnFile:\n",
    "            json.dump(json_neural_network, nnFile)\n",
    "\n",
    "    def _load(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        with open(OCRNeuralNetwork.NN_FILE_PATH) as nnFile:\n",
    "            nn = json.load(nnFile)\n",
    "        self.theta1 = [np.array(li) for li in nn['theta1']]\n",
    "        self.theta2 = [np.array(li) for li in nn['theta2']]\n",
    "        self.input_layer_bias = [np.array(nn['b1'][0])]\n",
    "        self.hidden_layer_bias = [np.array(nn['b2'][0])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
