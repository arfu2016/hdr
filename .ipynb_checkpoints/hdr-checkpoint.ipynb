{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hand-written digit recognition (hdr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "import math\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "This class does some initial training of a neural network for predicting drawn\n",
    "digits based on a data set in data_matrix and data_labels. It can then be used to\n",
    "train the network further by calling train() with any array of data or to predict\n",
    "what a drawn digit is by calling predict().\n",
    "\n",
    "The weights that define the neural network can be saved to a file, NN_FILE_PATH,\n",
    "to be reloaded upon initilization.\n",
    "\"\"\"\n",
    "\n",
    "class HdrNeuralNetwork:\n",
    "    WIDTH_IN_PIXELS = 20\n",
    "    LEARNING_RATE = 0.1\n",
    "    # for online learning\n",
    "    NN_FILE_PATH = 'nn.json'\n",
    "\n",
    "    def __init__(self, num_hidden_nodes, data_matrix, data_labels, use_file=True):\n",
    "        self.LAMBDA = 0\n",
    "        # for regularization of the cost function\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self.sigmoid = np.vectorize(self._sigmoid_scalar)\n",
    "        self.sigmoid_prime = np.vectorize(self._sigmoid_prime_scalar)\n",
    "        self._use_file = use_file\n",
    "        self.data_matrix = data_matrix # 2-D list\n",
    "        self.data_labels = data_labels # 1-D list\n",
    "        self.sample_num = len(self.data_labels)\n",
    "\n",
    "        if (not os.path.isfile(HdrNeuralNetwork.NN_FILE_PATH) or not use_file):\n",
    "            # Step 1: Initialize weights to small numbers\n",
    "            self.theta1 = self._rand_initialize_weights(self.num_hidden_nodes, 400+1)\n",
    "            # num_hidden_nodes*401 matrix, the one is the bias\n",
    "            self.theta2 = self._rand_initialize_weights(10, self.num_hidden_nodes+1)\n",
    "            # 10*(num_hidden_nodes+1) matrix, the one is the bias\n",
    "\n",
    "            # Train using sample data\n",
    "            TrainData = namedtuple('TrainData', ['fig', 'label'])\n",
    "            the_temp = tuple(np.row_stack((self.theta1.flatten(1).T, self.theta2.flatten(1).T)).T.tolist()[0])\n",
    "            theta0 = np.asarray(the_temp) \n",
    "            args = tuple([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)])\n",
    "            print 'Values of the cost function:'\n",
    "            \n",
    "            res = optimize.fmin_cg(self.nnCostFunction, theta0, fprime=self.nnGrad, args=args, gtol=1e-3, maxiter=200)\n",
    "            # gtol=1e-5, 1e-3; maxiter=None, 2, 200*6175 (default?), 1*6175, 200, 50, 100\n",
    "            res = np.mat(res)\n",
    "            self.theta1 = np.reshape(res[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "            self.theta2 = np.reshape(res[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "            # self.train([TrainData(self.data_matrix[i], int(self.data_labels[i])) for i in range(self.sample_num)])\n",
    "\n",
    "            self.save()\n",
    "        else:\n",
    "            self._load()\n",
    "\n",
    "    def _rand_initialize_weights(self, size_in, size_out):\n",
    "        return np.mat(np.random.rand(size_out, size_in)*0.24-0.12)\n",
    "\n",
    "    # The sigmoid activation function. Operates on scalars.\n",
    "    def _sigmoid_scalar(self, z):\n",
    "        return 1 / (1 + math.e ** -z)\n",
    "\n",
    "    def _sigmoid_prime_scalar(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def _draw(self, sample):\n",
    "        pixelArray = [sample[j:j+self.WIDTH_IN_PIXELS] for j in xrange(0, len(sample), self.WIDTH_IN_PIXELS)]\n",
    "        plt.imshow(zip(*pixelArray), cmap = cm.Greys_r, interpolation=\"nearest\")\n",
    "        plt.show()\n",
    "\n",
    "    def nnCostFunction(self, the_thetas, *args):\n",
    "        \n",
    "        the_thetas = np.mat(the_thetas)\n",
    "        theta1 = np.reshape(the_thetas[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "        theta2 = np.reshape(the_thetas[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "        training_data_array = args\n",
    "        \n",
    "        J=0        \n",
    "        for data in training_data_array:\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (3 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list          \n",
    "            \n",
    "            for j in range(10):\n",
    "                J = J + np.mat(y).T[j,0]*math.log(a3[j,0])+(1-np.mat(y).T[j,0])*math.log(1-a3[j,0])\n",
    "                # numerically a3[j,0] could be smaller than 0 or larger than 1 a bit\n",
    "\n",
    "        J = -J/self.sample_num + self.LAMBDA/(2*self.sample_num)*(np.multiply(theta1[:,1:], theta1[:,1:]).sum()+np.multiply(theta2[:,1:], theta2[:,1:]).sum())\n",
    "        print J \n",
    "        \n",
    "        return J\n",
    "        \n",
    "    def nnGrad(self, the_thetas, *args):\n",
    "        \n",
    "        the_thetas = np.mat(the_thetas)\n",
    "        theta1 = np.reshape(the_thetas[0,0:self.num_hidden_nodes*401], (400+1, self.num_hidden_nodes)).T\n",
    "        theta2 = np.reshape(the_thetas[0,self.num_hidden_nodes*401:], (self.num_hidden_nodes+1, 10)).T\n",
    "        training_data_array = args\n",
    "        \n",
    "        Delta1 = np.mat(np.zeros(theta1.shape))\n",
    "        # num_hidden_nodes*401 matrix\n",
    "        Delta2 = np.mat(np.zeros(theta2.shape))\n",
    "        # 10*(num_hidden_nodes+1) matrix\n",
    "        theta1_grad = np.mat(np.zeros(theta1.shape))\n",
    "        theta2_grad = np.mat(np.zeros(theta2.shape))\n",
    "        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "            \n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list\n",
    "                      \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.row_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(theta2.T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # num_hidden_nodes*1 matrix\n",
    "                      \n",
    "            # Step 4: Sum delta*a.T and calculate the derivatives\n",
    "            Delta1 = Delta1 + np.dot(delta2, np.row_stack((1, a1)).T)\n",
    "            Delta2 = Delta2 + np.dot(delta3, np.row_stack((1, a2)).T)\n",
    "        \n",
    "        theta1_grad[:,0] = Delta1[:,0]/self.sample_num\n",
    "        theta2_grad[:,0] = Delta2[:,0]/self.sample_num\n",
    "        theta1_grad[:,1:] = Delta1[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta1[:,1:]\n",
    "        theta2_grad[:,1:] = Delta2[:,1:]/self.sample_num + self.LAMBDA/self.sample_num*theta2[:,1:] \n",
    "        \n",
    "        ret = tuple(np.row_stack((theta1_grad.flatten(1).T, theta2_grad.flatten(1).T)).T.tolist()[0])\n",
    "        return np.asarray(ret)\n",
    "\n",
    "    def train(self, training_data_array):        \n",
    "        for data in training_data_array:\n",
    "            # Step 2: Forward propagation\n",
    "            a1 = np.mat(data.fig).T\n",
    "            # 400*1 matrix\n",
    "            z2 = np.dot(theta1, np.row_stack((1, a1)))\n",
    "            # num_hidden_nodes*1 matrix\n",
    "            a2 = self.sigmoid(z2)\n",
    "\n",
    "            z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "            # 10*1 matrix\n",
    "            a3 = self.sigmoid(z3)\n",
    "\n",
    "            # Step 3: Back propagation\n",
    "            y = [0] * 10 # y is a python list for easy initialization and is later turned into an np matrix (2 lines down).\n",
    "            y[data.label] = 1\n",
    "            # 1*10 list\n",
    "                      \n",
    "            delta3 = a3 - np.mat(y).T\n",
    "            # 10*1 matrix\n",
    "            z2plus = np.row_stack((0, z2))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = np.multiply(np.dot(theta2.T, delta3), self.sigmoid_prime(z2plus))\n",
    "            # (num_hidden_nodes+1)*1 matrix\n",
    "            delta2 = delta2[1:,0]\n",
    "            # num_hidden_nodes*1 matrix\n",
    "\n",
    "            # Step 4: Update weights\n",
    "            self.theta1 -= self.LEARNING_RATE * np.dot(delta2, np.row_stack((1, a1)).T)\n",
    "            self.theta2 -= self.LEARNING_RATE * np.dot(delta3, np.row_stack((1, a2)).T)\n",
    "\n",
    "    def predict(self, test):\n",
    "        a1 = np.mat(test).T\n",
    "        # 400*1 matrix\n",
    "        z2 = np.dot(self.theta1, np.row_stack((1, a1)))\n",
    "        # num_hidden_nodes*1 matrix\n",
    "        a2 = self.sigmoid(z2)\n",
    "\n",
    "        z3 = np.dot(theta2, np.row_stack((1, a2)))\n",
    "        # 10*1 matrix\n",
    "        a3 = self.sigmoid(z3)        \n",
    "\n",
    "        results = a3.T.tolist()[0]\n",
    "        return results.index(max(results))\n",
    "\n",
    "    def save(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        json_neural_network = {\n",
    "            \"theta1\":self.theta1.flatten(1).tolist()[0],\n",
    "            \"theta2\":self.theta2.flatten(1).tolist()[0]\n",
    "        };\n",
    "        with open(HdrNeuralNetwork.NN_FILE_PATH,'w') as nnFile:\n",
    "            json.dump(json_neural_network, nnFile)\n",
    "            \n",
    "        print 'nn.json is now saved'\n",
    "\n",
    "    def _load(self):\n",
    "        if not self._use_file:\n",
    "            return\n",
    "\n",
    "        with open(HdrNeuralNetwork.NN_FILE_PATH) as nnFile:\n",
    "            nn = json.load(nnFile)\n",
    "        self.theta1 = np.reshape(np.mat(nn['theta1']), (400+1, self.num_hidden_nodes)).T \n",
    "        self.theta2 = np.reshape(np.mat(nn['theta2']), (self.num_hidden_nodes+1, 10)).T \n",
    "        \n",
    "        print 'reloading previous nn.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the cost function:\n",
      "6.8391280027\n",
      "3.29306871621\n",
      "3.25135450196\n",
      "3.25051175477\n",
      "3.24996781942\n",
      "3.24736113674\n",
      "3.24089645032\n",
      "3.2384621125\n",
      "3.2297818248\n",
      "3.214651583\n",
      "3.15589329473\n",
      "3.08554432006\n",
      "3.06054027443\n",
      "2.85236611761\n",
      "2.5024463618\n",
      "2.11606160178\n",
      "2.01206142319\n",
      "1.88227360753\n",
      "1.80358844074\n",
      "1.68392263849\n",
      "1.57487275652\n",
      "1.49274089913\n",
      "1.45108283776\n",
      "1.38018312072\n",
      "1.34287991788\n",
      "1.25744096424\n",
      "1.22632059748\n",
      "1.18666259253\n",
      "1.1607289018\n",
      "1.09177341468\n",
      "1.06165213286\n",
      "1.02405620281\n",
      "1.00353377423\n",
      "0.965606221548\n",
      "0.942265685836\n",
      "0.892674502161\n",
      "0.874269916689\n",
      "0.833186951734\n",
      "0.817115711016\n",
      "0.779904106323\n",
      "0.768758046408\n",
      "0.746136348163\n",
      "0.734028629089\n",
      "0.699077804394\n",
      "0.684532560756\n",
      "0.663865487905\n",
      "0.646212585668\n",
      "0.635822318879\n",
      "0.612178106704\n",
      "0.604594777385\n",
      "0.595766889903\n",
      "0.591760769256\n",
      "0.581967626286\n",
      "0.578259345652\n",
      "0.572198119833\n",
      "0.568721831919\n",
      "0.558939233159\n",
      "0.555871231294\n",
      "0.550029086567\n",
      "0.542457965248\n",
      "0.538323768474\n",
      "0.527902355887\n",
      "0.525338514843\n",
      "0.519620894307\n",
      "0.518306411944\n",
      "0.51454597105\n",
      "0.513207240586\n",
      "0.510719570137\n",
      "0.504649961416\n",
      "0.501962646047\n",
      "0.497507914521\n",
      "0.495354601986\n",
      "0.490191878375\n",
      "0.488578839715\n",
      "0.486352099251\n",
      "0.485306742687\n",
      "0.482037285516\n",
      "0.479900810017\n",
      "0.476556479571\n",
      "0.468392407091\n",
      "0.466267307565\n",
      "0.461198134584\n",
      "0.459717372767\n",
      "0.45655713517\n",
      "0.45541760978\n",
      "0.452214529939\n",
      "0.451231987425\n",
      "0.449723772965\n",
      "0.4464562763\n",
      "0.443883611702\n",
      "0.436435444142\n",
      "0.433519750045\n",
      "0.429998356797\n",
      "0.422901484559\n",
      "0.419951355475\n",
      "0.411691596615\n",
      "0.409027888642\n",
      "0.404585608541\n",
      "0.393340130884\n",
      "0.389737571497\n",
      "0.38530025841\n",
      "0.383917713792\n",
      "0.382095329018\n",
      "0.380899691422\n",
      "0.378345190918\n",
      "0.377713847093\n",
      "0.376240615056\n",
      "0.375754666883\n",
      "0.374696915105\n",
      "0.373991903198\n",
      "0.371835173172\n",
      "0.370576569101\n",
      "0.369237313685\n",
      "0.365535258014\n",
      "0.364528634082\n",
      "0.361167041281\n",
      "0.351033625465\n",
      "0.345925582686\n",
      "0.339987410753\n",
      "0.331368195982\n",
      "0.328103356974\n",
      "0.320756248386\n",
      "0.317003683402\n",
      "0.310691584812\n",
      "0.307395150639\n",
      "0.300058080845\n",
      "0.297836990864\n",
      "0.294292297512\n",
      "0.292733675049\n",
      "0.288727492299\n",
      "0.286972152657\n",
      "0.284552081702\n",
      "0.2833917631\n",
      "0.280407455882\n",
      "0.278777684561\n",
      "0.276209752064\n",
      "0.275453924337\n",
      "0.27378056811\n",
      "0.272337889112\n",
      "0.269461081152\n",
      "0.268603788788\n",
      "0.265932941804\n",
      "0.26418455586\n",
      "0.262898430374\n",
      "0.260496076413\n",
      "0.259653625954\n",
      "0.258128116654\n",
      "0.257690177928\n",
      "0.25623214412\n",
      "0.254652319633\n",
      "0.253368087425\n",
      "0.251453249096\n",
      "0.250172286485\n",
      "0.248484504042\n",
      "0.247730243341\n",
      "0.245675747265\n",
      "0.245053608786\n",
      "0.243293186902\n",
      "0.242696059913\n",
      "0.241846426558\n",
      "0.239873702811\n",
      "0.238661693722\n",
      "0.237270488096\n",
      "0.236743144147\n",
      "0.23583960095\n",
      "0.234956482196\n",
      "0.23224151346\n",
      "0.230602019707\n",
      "0.229670992287\n",
      "0.227332089992\n",
      "0.226565488181\n",
      "0.225377676238\n",
      "0.224655138351\n",
      "0.223802587373\n",
      "0.223166515003\n",
      "0.222123378453\n",
      "0.22163949747\n",
      "0.221019071613\n",
      "0.220390022763\n",
      "0.21911193681\n",
      "0.218374841761\n",
      "0.21667846822\n",
      "0.21621860044\n",
      "0.215654825913\n",
      "0.215126440101\n",
      "0.214176986973\n",
      "0.213374833854\n",
      "0.212490819236\n",
      "0.211294408621\n",
      "0.209142756172\n",
      "0.208243132053\n",
      "0.207078494946\n",
      "0.206133781899\n",
      "0.205394643662\n",
      "0.204625116548\n",
      "0.202990116875\n",
      "0.20228844586\n",
      "0.20159571621\n",
      "0.200736416291\n",
      "0.199226238704\n",
      "0.198238858378\n",
      "0.197455794728\n",
      "0.196413329737\n",
      "0.195037057641\n",
      "0.194139349653\n",
      "0.19251578194\n",
      "0.191459800805\n",
      "0.190748392026\n",
      "0.189845211185\n",
      "0.187812801661\n",
      "0.186943837096\n",
      "0.186299225946\n",
      "0.185574867445\n",
      "0.184527957176\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.184528\n",
      "         Iterations: 100\n",
      "         Function evaluations: 214\n",
      "         Gradient evaluations: 214\n",
      "nn.json is now saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "HIDDEN_NODE_COUNT = 15\n",
    "data_matrix = np.loadtxt(open('data.csv', 'rb'), delimiter = ',')\n",
    "data_labels = np.loadtxt(open('dataLabels.csv', 'rb'))\n",
    "\n",
    "data_matrix = data_matrix.tolist()\n",
    "# print data_matrix[0:2]\n",
    "data_labels = data_labels.tolist()\n",
    "# print data_labels[0:2]\n",
    "\n",
    "nn = HdrNeuralNetwork(HIDDEN_NODE_COUNT, data_matrix, data_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
